{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# os.chdir(\"./unet\")\n",
    "from config import *\n",
    "from unet_config import Config\n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_unet = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training_images = len(glob.glob(TRAIN_IMAGE_FOLDER + SAT_IMAGE_FOLDER + \"/0/*.png\"))\n",
    "num_testing_images = len(glob.glob(TEST_IMAGE_FOLDER + SAT_IMAGE_FOLDER + \"/0/*.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_data(num_images_to_get=32, normalise=True, image_folder = TRAIN_IMAGE_FOLDER):\n",
    "    # Get list of files\n",
    "    satellite_images = glob.glob(image_folder + SAT_IMAGE_FOLDER + \"/0/*.png\")\n",
    "    if normalise:\n",
    "        # first provide a sample of images for featurewise normalisation\n",
    "        X_sample, y_sample = next(get_image_data(num_images_to_get=1000, normalise=False))\n",
    "\n",
    "        mean_sat_color = np.mean(X_sample.reshape(X_sample.shape[0]*X_sample.shape[1]*X_sample.shape[2], 3), axis=0)\n",
    "        variance_sat_color = np.var(X_sample.reshape(X_sample.shape[0]*X_sample.shape[1]*X_sample.shape[2], 3), axis=0)\n",
    "\n",
    "        #mean_mask_color = np.mean(y_sample.reshape(y_sample.shape[0]*y_sample.shape[1]*y_sample.shape[2], 1), axis=0)\n",
    "        #variance_mask_color = np.var(y_sample.reshape(y_sample.shape[0]*y_sample.shape[1]*y_sample.shape[2], 1), axis=0)\n",
    "        \n",
    "        del X_sample\n",
    "        del y_sample\n",
    "\n",
    "    while True:\n",
    "        np.random.shuffle(satellite_images)\n",
    "\n",
    "        # Preallocate array of image stacks\n",
    "        satellite_stacked = np.zeros((num_images_to_get, 224, 224, 3), dtype=np.float32)\n",
    "        mask_stacked = np.zeros((num_images_to_get, 224, 224, 1), dtype=np.float32)\n",
    "\n",
    "        for i, image in enumerate(satellite_images[:num_images_to_get]):\n",
    "            image = image.split(\"/\")[-1]\n",
    "            satellite_stacked[i] = np.array(Image.open(image_folder + SAT_IMAGE_FOLDER + \"/0/\" + image))\n",
    "            mask_stacked[i] = np.array(Image.open(image_folder + MASK_IMAGE_FOLDER + \"/0/\" + image)).reshape(224,224, 1)/255.0\n",
    "\n",
    "        if normalise:\n",
    "            satellite_stacked = (satellite_stacked - mean_sat_color)/np.sqrt(variance_sat_color)\n",
    "            #mask_stacked = (mask_stacked - mean_mask_color)/np.sqrt(variance_mask_color)\n",
    "        yield satellite_stacked, mask_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(WEIGHTS_FOLDER, exist_ok=True)\n",
    "model_checkpoint = ModelCheckpoint(os.path.join(WEIGHTS_FOLDER,'unet_tversky.hdf5'), monitor='tversky', save_best_only=True)\n",
    "tb_callback = TensorBoard(log_dir=LOGS_FOLDER + \"/tversky_α_0.3_β_0.7/\", histogram_freq=0, batch_size=config_unet.BATCH_SIZE,\n",
    "                          write_graph=True, write_grads=False, write_images=True,\n",
    "                          embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "# start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import get_vgg_7conv\n",
    "import metrics\n",
    "import losses\n",
    "\n",
    "model = get_vgg_7conv(config_unet.ISZ, config_unet.N_CHANNELS, config_unet.NUM_CLASSES)\n",
    "model.load_weights(\"model.h5\")\n",
    "model.compile(\n",
    "    optimizer=Adam(lr=0.001),\n",
    "     loss=losses.tversky_loss,\n",
    "    metrics=[\n",
    "        metrics.jaccard_coef, metrics.jacard_coef_flat,\n",
    "        metrics.jaccard_coef_int, metrics.dice_coef, 'accuracy'\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/keras/callbacks.py:999: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "250/250 [==============================] - 387s 2s/step - loss: 0.1192 - jaccard_coef: 0.7680 - jacard_coef_flat: 0.7872 - jaccard_coef_int: 0.7707 - dice_coef: 0.8785 - acc: 0.9960 - val_loss: 0.3193 - val_jaccard_coef: 0.4027 - val_jacard_coef_flat: 0.4160 - val_jaccard_coef_int: 0.4029 - val_dice_coef: 0.5819 - val_acc: 0.9797\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/keras/callbacks.py:432: RuntimeWarning: Can save best model only with tversky available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 378s 2s/step - loss: 0.1341 - jaccard_coef: 0.7407 - jacard_coef_flat: 0.7641 - jaccard_coef_int: 0.7447 - dice_coef: 0.8626 - acc: 0.9954 - val_loss: 0.1266 - val_jaccard_coef: 0.7426 - val_jacard_coef_flat: 0.7657 - val_jaccard_coef_int: 0.7443 - val_dice_coef: 0.8657 - val_acc: 0.9954\n",
      "Epoch 3/20\n",
      "250/250 [==============================] - 380s 2s/step - loss: 0.1189 - jaccard_coef: 0.7714 - jacard_coef_flat: 0.7912 - jaccard_coef_int: 0.7732 - dice_coef: 0.8808 - acc: 0.9959 - val_loss: 0.1402 - val_jaccard_coef: 0.7352 - val_jacard_coef_flat: 0.7568 - val_jaccard_coef_int: 0.7366 - val_dice_coef: 0.8603 - val_acc: 0.9959\n",
      "Epoch 4/20\n",
      "250/250 [==============================] - 378s 2s/step - loss: 0.1117 - jaccard_coef: 0.7725 - jacard_coef_flat: 0.7958 - jaccard_coef_int: 0.7762 - dice_coef: 0.8846 - acc: 0.9964 - val_loss: 0.1323 - val_jaccard_coef: 0.7350 - val_jacard_coef_flat: 0.7546 - val_jaccard_coef_int: 0.7362 - val_dice_coef: 0.8582 - val_acc: 0.9955\n",
      "Epoch 5/20\n",
      "250/250 [==============================] - 380s 2s/step - loss: 0.1106 - jaccard_coef: 0.7771 - jacard_coef_flat: 0.7969 - jaccard_coef_int: 0.7798 - dice_coef: 0.8854 - acc: 0.9963 - val_loss: 0.1619 - val_jaccard_coef: 0.7158 - val_jacard_coef_flat: 0.7454 - val_jaccard_coef_int: 0.7200 - val_dice_coef: 0.8516 - val_acc: 0.9957\n",
      "Epoch 6/20\n",
      "250/250 [==============================] - 378s 2s/step - loss: 0.1112 - jaccard_coef: 0.7777 - jacard_coef_flat: 0.7977 - jaccard_coef_int: 0.7805 - dice_coef: 0.8858 - acc: 0.9963 - val_loss: 0.1416 - val_jaccard_coef: 0.7316 - val_jacard_coef_flat: 0.7546 - val_jaccard_coef_int: 0.7364 - val_dice_coef: 0.8586 - val_acc: 0.9960\n",
      "Epoch 7/20\n",
      "250/250 [==============================] - 380s 2s/step - loss: 0.1024 - jaccard_coef: 0.7880 - jacard_coef_flat: 0.8109 - jaccard_coef_int: 0.7925 - dice_coef: 0.8941 - acc: 0.9966 - val_loss: 0.1356 - val_jaccard_coef: 0.7150 - val_jacard_coef_flat: 0.7475 - val_jaccard_coef_int: 0.7169 - val_dice_coef: 0.8541 - val_acc: 0.9955\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 8/20\n",
      "250/250 [==============================] - 380s 2s/step - loss: 0.1034 - jaccard_coef: 0.7932 - jacard_coef_flat: 0.8120 - jaccard_coef_int: 0.7967 - dice_coef: 0.8944 - acc: 0.9966 - val_loss: 0.1313 - val_jaccard_coef: 0.7429 - val_jacard_coef_flat: 0.7620 - val_jaccard_coef_int: 0.7454 - val_dice_coef: 0.8638 - val_acc: 0.9958\n",
      "Epoch 9/20\n",
      "250/250 [==============================] - 379s 2s/step - loss: 0.0956 - jaccard_coef: 0.8017 - jacard_coef_flat: 0.8235 - jaccard_coef_int: 0.8055 - dice_coef: 0.9021 - acc: 0.9969 - val_loss: 0.1353 - val_jaccard_coef: 0.7303 - val_jacard_coef_flat: 0.7608 - val_jaccard_coef_int: 0.7325 - val_dice_coef: 0.8620 - val_acc: 0.9959\n",
      "Epoch 10/20\n",
      "250/250 [==============================] - 380s 2s/step - loss: 0.0994 - jaccard_coef: 0.7988 - jacard_coef_flat: 0.8200 - jaccard_coef_int: 0.8029 - dice_coef: 0.8996 - acc: 0.9966 - val_loss: 0.1317 - val_jaccard_coef: 0.7338 - val_jacard_coef_flat: 0.7560 - val_jaccard_coef_int: 0.7358 - val_dice_coef: 0.8597 - val_acc: 0.9958\n",
      "Epoch 11/20\n",
      "250/250 [==============================] - 379s 2s/step - loss: 0.0918 - jaccard_coef: 0.8081 - jacard_coef_flat: 0.8298 - jaccard_coef_int: 0.8127 - dice_coef: 0.9060 - acc: 0.9970 - val_loss: 0.1373 - val_jaccard_coef: 0.7159 - val_jacard_coef_flat: 0.7406 - val_jaccard_coef_int: 0.7185 - val_dice_coef: 0.8493 - val_acc: 0.9958\n",
      "Epoch 12/20\n",
      "250/250 [==============================] - 381s 2s/step - loss: 0.0927 - jaccard_coef: 0.8106 - jacard_coef_flat: 0.8289 - jaccard_coef_int: 0.8136 - dice_coef: 0.9051 - acc: 0.9969 - val_loss: 0.1417 - val_jaccard_coef: 0.7330 - val_jacard_coef_flat: 0.7588 - val_jaccard_coef_int: 0.7374 - val_dice_coef: 0.8616 - val_acc: 0.9957\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 13/20\n",
      "250/250 [==============================] - 378s 2s/step - loss: 0.0919 - jaccard_coef: 0.8116 - jacard_coef_flat: 0.8311 - jaccard_coef_int: 0.8152 - dice_coef: 0.9064 - acc: 0.9968 - val_loss: 0.1248 - val_jaccard_coef: 0.7548 - val_jacard_coef_flat: 0.7796 - val_jaccard_coef_int: 0.7553 - val_dice_coef: 0.8752 - val_acc: 0.9960\n",
      "Epoch 14/20\n",
      "250/250 [==============================] - 380s 2s/step - loss: 0.0872 - jaccard_coef: 0.8216 - jacard_coef_flat: 0.8390 - jaccard_coef_int: 0.8246 - dice_coef: 0.9112 - acc: 0.9970 - val_loss: 0.1356 - val_jaccard_coef: 0.7301 - val_jacard_coef_flat: 0.7559 - val_jaccard_coef_int: 0.7324 - val_dice_coef: 0.8591 - val_acc: 0.9958\n",
      "Epoch 15/20\n",
      "250/250 [==============================] - 378s 2s/step - loss: 0.0851 - jaccard_coef: 0.8224 - jacard_coef_flat: 0.8419 - jaccard_coef_int: 0.8274 - dice_coef: 0.9132 - acc: 0.9971 - val_loss: 0.1323 - val_jaccard_coef: 0.7480 - val_jacard_coef_flat: 0.7676 - val_jaccard_coef_int: 0.7533 - val_dice_coef: 0.8664 - val_acc: 0.9960\n",
      "Epoch 16/20\n",
      "250/250 [==============================] - 381s 2s/step - loss: 0.0857 - jaccard_coef: 0.8216 - jacard_coef_flat: 0.8408 - jaccard_coef_int: 0.8261 - dice_coef: 0.9125 - acc: 0.9971 - val_loss: 0.1337 - val_jaccard_coef: 0.7255 - val_jacard_coef_flat: 0.7521 - val_jaccard_coef_int: 0.7270 - val_dice_coef: 0.8570 - val_acc: 0.9958\n",
      "Epoch 17/20\n",
      "250/250 [==============================] - 378s 2s/step - loss: 0.0813 - jaccard_coef: 0.8261 - jacard_coef_flat: 0.8461 - jaccard_coef_int: 0.8299 - dice_coef: 0.9159 - acc: 0.9972 - val_loss: 0.1336 - val_jaccard_coef: 0.7385 - val_jacard_coef_flat: 0.7610 - val_jaccard_coef_int: 0.7390 - val_dice_coef: 0.8624 - val_acc: 0.9957\n",
      "Epoch 18/20\n",
      "250/250 [==============================] - 379s 2s/step - loss: 0.0855 - jaccard_coef: 0.8237 - jacard_coef_flat: 0.8433 - jaccard_coef_int: 0.8285 - dice_coef: 0.9139 - acc: 0.9973 - val_loss: 0.1295 - val_jaccard_coef: 0.7375 - val_jacard_coef_flat: 0.7666 - val_jaccard_coef_int: 0.7416 - val_dice_coef: 0.8659 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 19/20\n",
      "250/250 [==============================] - 379s 2s/step - loss: 0.0863 - jaccard_coef: 0.8250 - jacard_coef_flat: 0.8425 - jaccard_coef_int: 0.8285 - dice_coef: 0.9129 - acc: 0.9968 - val_loss: 0.1267 - val_jaccard_coef: 0.7456 - val_jacard_coef_flat: 0.7722 - val_jaccard_coef_int: 0.7473 - val_dice_coef: 0.8700 - val_acc: 0.9961\n",
      "Epoch 20/20\n",
      "250/250 [==============================] - 379s 2s/step - loss: 0.0862 - jaccard_coef: 0.8276 - jacard_coef_flat: 0.8438 - jaccard_coef_int: 0.8321 - dice_coef: 0.9139 - acc: 0.9971 - val_loss: 0.1220 - val_jaccard_coef: 0.7442 - val_jacard_coef_flat: 0.7783 - val_jaccard_coef_int: 0.7472 - val_dice_coef: 0.8743 - val_acc: 0.9962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc31aff3898>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    get_image_data(num_images_to_get=config_unet.BATCH_SIZE, image_folder=TRAIN_IMAGE_FOLDER),\n",
    "    epochs=20, verbose=True,\n",
    "    steps_per_epoch=int(num_training_images/config_unet.BATCH_SIZE)//50*50,\n",
    "    validation_data=get_image_data(num_images_to_get=config_unet.BATCH_SIZE, image_folder=TEST_IMAGE_FOLDER),\n",
    "    validation_steps=int(num_testing_images/config_unet.BATCH_SIZE)//50*50,\n",
    "    callbacks=[model_checkpoint,\n",
    "               tb_callback,\n",
    "               ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-9, epsilon=0.00001, verbose=1, mode='min')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_tversky.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext_format_version": "1.1",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
