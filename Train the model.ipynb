{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the U-Net model and train it on our data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add unet model folder\n",
    "sys.path.append(\"unet/\")\n",
    "\n",
    "import config\n",
    "from model import get_vgg_7conv\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "## Uncomment this if you want to force tensorflow to use your CPUs instead (useful if you don't have a beefy GPU)\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training_images = len(glob.glob(config.TRAIN_IMAGE_FOLDER + config.SAT_IMAGE_FOLDER + \"/0/*.png\"))\n",
    "num_testing_images = len(glob.glob(config.TEST_IMAGE_FOLDER + config.SAT_IMAGE_FOLDER + \"/0/*.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: no images detected\n"
     ]
    }
   ],
   "source": [
    "if num_testing_images == 0 or num_training_images == 0:\n",
    "    print(\"WARNING: no images detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_data(num_images_to_get=32, normalise=True, image_folder = config.TRAIN_IMAGE_FOLDER, augment=False):\n",
    "    # Get list of files\n",
    "    satellite_images = glob.glob(image_folder + SAT_IMAGE_FOLDER + \"/0/*.png\")\n",
    "    if len(satellite_images) == 0:\n",
    "        raise FileNotFoundError(image_folder + SAT_IMAGE_FOLDER + \" doesn't contain any images!\")\n",
    "    if normalise:\n",
    "        # first provide a sample of images for featurewise normalisation\n",
    "        X_sample, y_sample = next(get_image_data(num_images_to_get=1000, normalise=False))\n",
    "\n",
    "        mean_sat_color = np.mean(X_sample.reshape(X_sample.shape[0]*X_sample.shape[1]*X_sample.shape[2], 3), axis=0)\n",
    "        variance_sat_color = np.var(X_sample.reshape(X_sample.shape[0]*X_sample.shape[1]*X_sample.shape[2], 3), axis=0)\n",
    "\n",
    "        #mean_mask_color = np.mean(y_sample.reshape(y_sample.shape[0]*y_sample.shape[1]*y_sample.shape[2], 1), axis=0)\n",
    "        #variance_mask_color = np.var(y_sample.reshape(y_sample.shape[0]*y_sample.shape[1]*y_sample.shape[2], 1), axis=0)\n",
    "        \n",
    "        del X_sample\n",
    "        del y_sample\n",
    "\n",
    "    while True:\n",
    "        np.random.shuffle(satellite_images)\n",
    "\n",
    "        # Preallocate array of image stacks\n",
    "        satellite_stacked = np.zeros((num_images_to_get, 224, 224, 3), dtype=np.float32)\n",
    "        mask_stacked = np.zeros((num_images_to_get, 224, 224, 1), dtype=np.float32)\n",
    "\n",
    "        for i, image in enumerate(satellite_images[:num_images_to_get]):\n",
    "            image = image.split(\"/\")[-1]\n",
    "            satellite_stacked[i] = np.array(Image.open(image_folder + SAT_IMAGE_FOLDER + \"/0/\" + image))\n",
    "            mask_stacked[i] = np.array(Image.open(image_folder + MASK_IMAGE_FOLDER + \"/0/\" + image)).reshape(224,224, 1)/255.0\n",
    "\n",
    "        if augment:\n",
    "            augmenters = iaa.SomeOf((0, None), [\n",
    "                iaa.WithChannels(0, iaa.Add((-20, 20))),\n",
    "                iaa.WithChannels(1, iaa.Add((-20, 20))),\n",
    "                iaa.WithChannels(2, iaa.Add((-20, 20))),\n",
    "                iaa.Sharpen(alpha=0.1),\n",
    "                iaa.GaussianBlur(sigma=(0, 2)),\n",
    "                iaa.AdditiveGaussianNoise(scale=(0,0.05*255)),\n",
    "            ])\n",
    "            satellite_stacked = augmenters.augment_images(satellite_stacked)\n",
    "        if normalise:\n",
    "            satellite_stacked = (satellite_stacked - mean_sat_color)/np.sqrt(variance_sat_color)\n",
    "            #mask_stacked = (mask_stacked - mean_mask_color)/np.sqrt(variance_mask_color)\n",
    "        yield satellite_stacked, mask_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(config.WEIGHTS_FOLDER, exist_ok=True)\n",
    "model_checkpoint = ModelCheckpoint(config.WEIGHTS_FOLDER + 'intermediate_models_with_aug.h5', monitor='dice_coef', save_best_only=True)\n",
    "tb_callback = TensorBoard(log_dir=config.LOGS_FOLDER, histogram_freq=0, batch_size=config.BATCH_SIZE,\n",
    "                          write_graph=True, write_grads=False, write_images=True,\n",
    "                          embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import metrics\n",
    "\n",
    "model = get_vgg_7conv(config.ISZ, config.N_CHANNELS, config.NUM_CLASSES)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(lr=0.001),\n",
    "    loss=dice_coef_loss,\n",
    "    metrics=[\n",
    "        metrics.jaccard_coef, metrics.jacard_coef_flat,\n",
    "        metrics.jaccard_coef_int, metrics.dice_coef, 'accuracy'\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/durand/Stuff/Sources/anaconda3/envs/PV_detection/lib/python3.6/site-packages/keras/callbacks.py:999: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`validation_steps=None` is only valid for a generator based on the `keras.utils.Sequence` class. Please specify `validation_steps` or use the `keras.utils.Sequence` class.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b80ffdc6cf33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     callbacks=[model_checkpoint,\n\u001b[1;32m      8\u001b[0m                \u001b[0mtb_callback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                ReduceLROnPlateau(monitor='val_dice_coef', factor=0.5, patience=5, min_lr=1e-9, epsilon=0.00001, verbose=1, mode='max')])\n\u001b[0m",
      "\u001b[0;32m~/Stuff/Sources/anaconda3/envs/PV_detection/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Stuff/Sources/anaconda3/envs/PV_detection/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Stuff/Sources/anaconda3/envs/PV_detection/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m     65\u001b[0m     if (val_gen and not isinstance(validation_data, Sequence) and\n\u001b[1;32m     66\u001b[0m             not validation_steps):\n\u001b[0;32m---> 67\u001b[0;31m         raise ValueError('`validation_steps=None` is only valid for a'\n\u001b[0m\u001b[1;32m     68\u001b[0m                          \u001b[0;34m' generator based on the `keras.utils.Sequence`'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                          \u001b[0;34m' class. Please specify `validation_steps` or use'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: `validation_steps=None` is only valid for a generator based on the `keras.utils.Sequence` class. Please specify `validation_steps` or use the `keras.utils.Sequence` class."
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    get_image_data(num_images_to_get=config.BATCH_SIZE, image_folder=config.TRAIN_IMAGE_FOLDER),\n",
    "    epochs=80, verbose=True,\n",
    "    steps_per_epoch=int(num_training_images/config.BATCH_SIZE)//50*50,\n",
    "    validation_data=get_image_data(num_images_to_get=config.BATCH_SIZE, image_folder=config.TEST_IMAGE_FOLDER),\n",
    "    validation_steps=int(num_testing_images/config.BATCH_SIZE)//50*50,\n",
    "    callbacks=[model_checkpoint,\n",
    "               tb_callback,\n",
    "               ReduceLROnPlateau(monitor='val_dice_coef', factor=0.5, patience=5, min_lr=1e-9, epsilon=0.00001, verbose=1, mode='max')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(WEIGHTS_FOLDER + \"/model_with_aug.h5\")"
   ]
  }
 ],
 "metadata": {
  "jupytext_formats": "ipynb,py",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
